{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50c9f6ad",
   "metadata": {},
   "source": [
    "# Importing data from BBR into a relational database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0296d49d",
   "metadata": {},
   "source": [
    "This document shows how to retrieve data from the Danish building registry, BBR, and insert it into a relational database for easier use. <br>\n",
    "\n",
    "As prerequisites, you need to be able to run Python and have a PostgresQL database ready with a table to receive the BBR data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7936ba9",
   "metadata": {},
   "source": [
    "# 1) Obtaining the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220eea17",
   "metadata": {},
   "source": [
    "1. Go to https://datafordeler.dk/ <br>\n",
    "Click on \"log in\" and create a new web user. You should get a user name and password to access datafordeler. <br>\n",
    "<br>\n",
    "2. With your username and password, log in to the datafordeler self-service to retrieve data: <br> https://selfservice.datafordeler.dk/ <br>\n",
    "<br>\n",
    "3. It's not intuitive, but your account is linked to several \"users\", each with different permissions. Check the Users tab (Brugere) - if you only have the user \"Webbruger\", you need to create a new one. Click on the + tab and create a service user with the \"user name and access code\" method.<br>\n",
    "<br>\n",
    "4. You are now ready to request public data on datafordeler. Go to the Downloads tab (Filudtræk). You should see an empty field - that's because you haven't requested data yet. To get access to data, you need to create a download. You have three choices:<br> - Clicking Opret will allow you to create a permanent download button, that is kept up to date and that you can use multiple times.<br> - Clicking Download will allow you to request a one-time download of the dataset.<br> - Clicking Predefined will allow you to download a dataset with a fixed set of parameters (instead of customizing everything). In particular, you can use Predefined to download the BBR dataset with only up-to-date entries, in JSON or XML format. <br>\n",
    "<br>\n",
    "5. You should now see a list of all available downloads. Give your download a name (Visningsnavn) and select BBR Totaludtræk in the list (or BBR Aktuelt Totaludtræk if using Predefined). Click Next. If you chose Opret or Download, you can now adjust a lot of parameters, such as downloading entries for only a specific municipality. If you used Predefined, the parameters are locked.<br><br>\n",
    "\n",
    "6. Click Save (Gem). You will be taken back to the Download tabs. If you used Opret or Predefined, you should see your data subscription there. You can modify or delete it if you don't think that you will need to download it again in the future. You will receive an email with information on how to get your data.<br>\n",
    "<br>\n",
    "7. Actually getting the data is a bit tricky: you cannot download it from Datafordeler directly. You need to use a FTP client like https://filezilla-project.org/ <br>\n",
    "Download and install FileZilla. When you launch it, enter the address provided in the email you got from Datafordeler, as well as your Datafordeler service user number (*not* your initial username: this is the user number you created in step 3) and password. Click Connect, and you should finally be able to see and download your files! \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211a5d95",
   "metadata": {},
   "source": [
    "### Note on file format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70421b40",
   "metadata": {},
   "source": [
    "Because BBR is a very large dataset (if you download the whole thing), your computer will run out of memory when trying to parse it in one chunk. For this reason, you might want to download it as an XML file. Python methods exist to parse XML files iteratively without running out of memory. But as far as I know if you want to do the same with JSON you have to create that kind of function yourself."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f1dc40",
   "metadata": {},
   "source": [
    "# 2) Parsing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd37471",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40de3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET # package to parse XML "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d82cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import reprlib # package to limit print size if you want to avoid very long prints. \n",
    "# If you have many very long prints, the notebook might crash when you open it later.\n",
    "# Tip: on Jupyter, press Esc then R then Y to reset a cell and delete its output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b0e9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "xmlfile='C:/Users/.../myfile.xml' #Write the location of your XML file here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f71a0c",
   "metadata": {},
   "source": [
    "### Parsing the XML file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7626129f",
   "metadata": {},
   "source": [
    "The following bit of code is useful if you're working with a small dataset - for instance BBR for one municipality. But running it on the entire BBR dataset might crash your computer. See \"Working with a large dataset\" below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fb05d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = ET.parse(xmlfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64738e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = tree.getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c870e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "root.findall(\"./\") #To see the various item categories that make up BBR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4035f5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "root.findall(\"./{http://data.gov.dk/schemas/bbr}BygningList/{http://data.gov.dk/schemas/bbr}Bygning/\") #To see all building parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c758f8fc",
   "metadata": {},
   "source": [
    "### Working with a large dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496d8afb",
   "metadata": {},
   "source": [
    "Because BBR is very large, we want to use the iterparse method to parse it item-by-item instead of all at once. The procedure will scan the BBR database. When it encounters a new element, it will check if it's a building. If it is, it will extract the data we want about this building, and insert it into the PostgresQL database. But first, we need to define some functions to help us with each of these steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74d2ea1",
   "metadata": {},
   "source": [
    "First, we create a dictionary of namespaces to avoid working with the \"http://....\" namespaces in all XML tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d547945",
   "metadata": {},
   "outputs": [],
   "source": [
    "nsmap = {} #creating a dictionary of namespaces\n",
    "for event, elem in ET.iterparse(xmlfile, events=('start-ns','end')):\n",
    "    if event=='start-ns':\n",
    "        ns, url = elem\n",
    "        nsmap[ns] = url\n",
    "    else:\n",
    "        elem.clear()\n",
    "        break\n",
    "print(reprlib.repr(nsmap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d52490",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixtag(ns, tag, nsmap): #this function helps us build tag names based on the namespaces above\n",
    "    return('{' + nsmap[ns] + '}' + tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63bc20f2",
   "metadata": {},
   "source": [
    "Then we create a function to extract all the information we need about a building from its XML node, and return it as a single tuple that will be inserted in our database later on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8c025a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_building_properties(elem): #extract data about a building, return it as a tuple. Add and remove items based on your needs, but the order in the tuple must correspond to the order of the columns in your database.\n",
    "    bbr_id= elem.find('{*}id_lokalId').text\n",
    "    municipality_nr= elem.find('{*}kommunekode').text\n",
    "    grund= elem.find('{*}grund').text\n",
    "    husnummer= elem.find('{*}husnummer').text\n",
    "    coord= elem.find('{*}byg404Koordinat').text\n",
    "    construction_year= elem.find('{*}byg026Opførelsesår').text\n",
    "    latest_renovation_year= elem.find('{*}byg027OmTilbygningsår').text\n",
    "    bbr_use_category= elem.find('{*}byg021BygningensAnvendelse').text\n",
    "    built_area= elem.find('{*}byg041BebyggetAreal').text\n",
    "    total_building_area= elem.find('{*}byg038SamletBygningsareal').text\n",
    "    n_floors= elem.find('{*}byg054AntalEtager').text\n",
    "    wall_material= elem.find('{*}byg032YdervæggensMateriale').text\n",
    "    roof_material= elem.find('{*}byg033Tagdækningsmateriale').text       \n",
    "    return (bbr_id, municipality_nr, grund, husnummer, coord, construction_year, latest_renovation_year, bbr_use_category, built_area, total_building_area, n_floors, wall_material, roof_material)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6604e1fe",
   "metadata": {},
   "source": [
    "Now all we need is a function to insert the tuples we get from get_building_properties into the database, and finally we can write code to parse the XML file iteratively, extract data with get_building_properties, and insert rows in the database."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1fdfaf9",
   "metadata": {},
   "source": [
    "# 3) Inserting in the PostgresQL database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa73201b",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1f1622",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg as pg # package to communicate between Python and PostgresQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc7e4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('database_parameters.txt','r') as f: # Text file containing parameters to connect to the database\n",
    "    params=f.read()\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18eb0312",
   "metadata": {},
   "source": [
    "### Insertion function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29ada23",
   "metadata": {},
   "source": [
    "Here the idea is to write a function that inserts one row into the database. You need to adjust the SQL code to fit the names of your table and columns. Remember that the order must be the same as in the get_building_properties function! Note: it is possible to write a slightly simpler function that inserts all rows at once, but that requires building a dictionary with all rows first - and we want to avoid this due to the size of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996df408",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_bbr1(row_tuple):\n",
    "    sql = \"INSERT INTO buildings(bbr_id, municipality_nr, grund, husnummer, coord, construction_year, latest_renovation_year, bbr_use_category, built_area, total_building_area, n_floors, wall_material, roof_material) VALUES(%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s) ON CONFLICT ON CONSTRAINT buildings_pkey DO UPDATE SET (bbr_id, municipality_nr, grund, husnummer, coord, construction_year, latest_renovation_year, bbr_use_category, built_area, total_building_area, n_floors, wall_material, roof_material) = (EXCLUDED.bbr_id, EXCLUDED.municipality_nr, EXCLUDED.grund, EXCLUDED.husnummer, EXCLUDED.coord, EXCLUDED.construction_year, EXCLUDED.latest_renovation_year, EXCLUDED.bbr_use_category, EXCLUDED.built_area, EXCLUDED.total_building_area, EXCLUDED.n_floors, EXCLUDED.wall_material, EXCLUDED.roof_material);\"\n",
    "    #Replace table and column names by the ones in your PostgresQL database.\n",
    "    connector = None\n",
    "    bbrid = None\n",
    "    try:\n",
    "        # connect to the PostgreSQL database\n",
    "        connector = pg.connect(params)\n",
    "        # create a new cursor\n",
    "        cur = connector.cursor()\n",
    "        # execute the INSERT statement\n",
    "        cur.execute(sql, row_tuple)\n",
    "        # commit the changes to the database\n",
    "        connector.commit()\n",
    "        # close communication with the database\n",
    "        cur.close()\n",
    "    except (Exception, pg.DatabaseError) as error:\n",
    "        print(error)\n",
    "    finally:\n",
    "        if connector is not None:\n",
    "            connector.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33ae789",
   "metadata": {},
   "source": [
    "# 4) Running the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e8f883",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_database(xml):\n",
    "    for event, elem in ET.iterparse(xml): #The code starts scanning through each branch of the XML tree and records whenever it reaches the start and end of an object.\n",
    "        if elem.tag == fixtag('', 'BBRSag', nsmap): #When we reach the end of BBRSag and BBRSagList, print a check and clear the memory.\n",
    "            print('reached end of BBRSag')\n",
    "            elem.clear()\n",
    "        elif elem.tag == fixtag('', 'BBRSagList', nsmap): \n",
    "            print('reached end of BBRSagList')\n",
    "            elem.clear()    \n",
    "        elif elem.tag == fixtag('', 'Bygning', nsmap): #When we reach the end of a building node, get that building's properties and insert them as a row in the PostgresQL table. Clear the memory after each building.\n",
    "            row= get_building_properties(elem)\n",
    "            insert_bbr1(row)\n",
    "            elem.clear()\n",
    "        elif elem.tag == fixtag('', 'BygningList', nsmap):\n",
    "            print('reached end of building list') #The idea is to stop once we reach the end of the building list. For some reason it seems to never reach this point, the code just keeps running without adding building to the database. So check once in a while if the number of buildings in the database is still increasing; if not break manually.\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afb3833",
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_database(xmlfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
